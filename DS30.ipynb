{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science\n",
    "\n",
    "\n",
    "1. Python strikes a good balance between flexibility (it's interpreted) and speed (core machine-learning and linear algebra is in c via [cython](http://cython.org/)).\n",
    "1. Python strikes a good balance between being a programming language (it has a lot of language support built up by the community) and specialized machine-learning routines (e.g. [numpy](http://www.numpy.org/), [scipy](http://www.scipy.org/), [scikit learn](http://scikit-learn.org/), [pandas](http://pandas.pydata.org/)).\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing graphics related libraries\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns  # plots are prettier with Seaborn\n",
    "import onlineldavb\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']\n",
    "\n",
    "# importing useful libraries\n",
    "import simplejson\n",
    "import sys\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "from collections import Counter\n",
    "import heapq\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from itertools import islice, chain\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup twitter authorization\n",
    "\n",
    "1. Need to authenticate (can you guess why?).  Creat a twitter account and get your API credentials on the [Twitter API page](http://apps.twitter.com/).\n",
    "1. Secrets not checked into source control (good practice)!\n",
    "1. Using python `stream` (like an infinite list!)\n",
    "1. Handle stream using python `generator`\n",
    "1. *Protip*: `simplejson` is faster than builtin `json`.\n",
    "1. *Protip*: `requests` is easier to use than builtin `urllib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'twitter_secrets.json.nogit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9296171dbd13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"twitter_secrets.json.nogit\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0msecrets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimplejson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m auth = OAuth1(\n\u001b[0;32m      5\u001b[0m     \u001b[0msecrets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"api_key\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'twitter_secrets.json.nogit'"
     ]
    }
   ],
   "source": [
    "with open(\"twitter_secrets.json.nogit\") as fh:\n",
    "    secrets = simplejson.loads(fh.read())\n",
    "\n",
    "auth = OAuth1(\n",
    "    secrets[\"api_key\"],\n",
    "    secrets[\"api_secret\"],\n",
    "    secrets[\"access_token\"],\n",
    "    secrets[\"access_token_secret\"]\n",
    ")\n",
    "\n",
    "US_BOUNDING_BOX = \"-125.00,24.94,-66.93,49.59\"\n",
    "def tweet_generator():\n",
    "    stream = requests.post('https://stream.twitter.com/1.1/statuses/filter.json',\n",
    "                         auth=auth,\n",
    "                         stream=True,\n",
    "                         data={\"locations\" : US_BOUNDING_BOX})\n",
    "    \n",
    "    for line in stream.iter_lines():\n",
    "        if not line:  # filter out keep-alive new lines\n",
    "            continue\n",
    "        tweet = simplejson.loads(line)\n",
    "        if 'text' in tweet:\n",
    "            yield tweet['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out twitter stream\n",
    "\n",
    "1. When handling streams, need to use `itertools` (`slice` -> `islice`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'islice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-db21434f91d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'islice' is not defined"
     ]
    }
   ],
   "source": [
    "for tweet in islice(tweet_generator(), 100):\n",
    "    print tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DISPLAY_EVERY = 20\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def nlargest(n, word_scores):\n",
    "    return heapq.nlargest(n, word_scores, key=lambda x: x[1])\n",
    "\n",
    "try:\n",
    "    for k, tweet in enumerate(islice(tweet_generator(), 1000)):\n",
    "        for word in tweet.lower().split():\n",
    "            if word not in stop:\n",
    "                counter[word] += 1\n",
    "        if k % DISPLAY_EVERY == (DISPLAY_EVERY - 1):\n",
    "            sys.stdout.write(\"\\r\" + str(nlargest(10, counter.items())))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    df = pd.DataFrame(nlargest(10, counter.items()), columns=['words', 'count'])\n",
    "    df.set_index('words').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "1. Lists of word counts not as useful\n",
    "1. Wordcloud: size of word ~ frequency (there's a library for that)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "try:\n",
    "    for k, tweet in enumerate(islice(tweet_generator(), 1000)):\n",
    "        for word in tweet.lower().split():\n",
    "            if word not in stop and 'http' not in word:\n",
    "                counter[word] += 1\n",
    "        if k % DISPLAY_EVERY == (DISPLAY_EVERY - 1):\n",
    "            wordcloud = WordCloud().fit_words(counter.items())\n",
    "            plt.axis(\"off\")\n",
    "            display.clear_output(wait=True)\n",
    "            plt.imshow(wordcloud)\n",
    "            display.display(plt.gcf())\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "CLUSTER_SIZE = 4\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=CLUSTER_SIZE)\n",
    "\n",
    "def batch(iterable, size):\n",
    "    \"\"\" batch(\"ABCDEFG\", 3) -> ABC DEF G \"\"\"\n",
    "    sourceiter = iter(iterable)\n",
    "    while True:\n",
    "        batchiter = islice(sourceiter, size)\n",
    "        yield chain([batchiter.next()], batchiter)\n",
    "\n",
    "with open(\"dictnostops.txt\") as fh:\n",
    "    words = [line.strip() for line in fh.readlines()]\n",
    "    word_to_index = { word: k for k, word in enumerate(words) }\n",
    "\n",
    "def wordclouds(wordcounts):\n",
    "    wordclouds = [WordCloud().fit_words(counts) for counts in wordcounts]\n",
    "    fig, axes = plt.subplots(2,2)\n",
    "    display.clear_output(wait=True)\n",
    "    for k, (ax, wordcloud) in enumerate(zip(axes.flatten(), wordclouds)):\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(wordcloud)\n",
    "        ax.set_title(\"Topic %d\" % k)\n",
    "    display.display(fig)\n",
    "    fig.clear()\n",
    "\n",
    "try:\n",
    "    for tweets in batch(islice(tweet_generator(), 1000), BATCH_SIZE):\n",
    "        mat = sp.sparse.dok_matrix((BATCH_SIZE, len(words)))\n",
    "        for row, tweet in enumerate(tweets):\n",
    "            for word in tweet.lower().split():\n",
    "                if word in word_to_index:\n",
    "                    mat[row, word_to_index[word]] = 1.\n",
    "        kmeans.partial_fit(mat.tocsr())\n",
    "        wordcounts = [\n",
    "            nlargest(50, zip(words, kmeans.cluster_centers_[i]))\n",
    "            for i in xrange(kmeans.n_clusters)\n",
    "        ]\n",
    "        wordclouds(wordcounts)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "D = 1e9\n",
    "BATCH_SIZE = 20\n",
    "olda = onlineldavb.OnlineLDA(words, K, D, 1./K, 1./K, 1024., 0.7)\n",
    "\n",
    "try:\n",
    "    for tweets in batch(islice(tweet_generator(), 1000), BATCH_SIZE):\n",
    "        olda.update_lambda(list(tweets))\n",
    "        wordclouds(olda.topic_words(50))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
